{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 4: Modeling Evaluation Conclusion and Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Model selections:](#Model-selections:)\n",
    "- [Multinomial Naive-Bayes](#Multinomial-Naive-Bayes)\n",
    "- [Logistic Regressions](#Logistic-Regressions)\n",
    "- [Random Forest](#Random-Forest)\n",
    "- [Evaluating Models](#Evaluating-Models)\n",
    "- [Conclusion and Recommendations](#Conclusion-and-Recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../datasets/X_train.csv', index_col = 0)\n",
    "X_test = pd.read_csv('../datasets/X_test.csv', index_col = 0)\n",
    "y_train = pd.read_csv('../datasets/y_train.csv', index_col = 0)\n",
    "y_test = pd.read_csv('../datasets/y_test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combine_text_tokens</th>\n",
       "      <th>combine_text_stem</th>\n",
       "      <th>combine_text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>the guy is a walking sugar cookie</td>\n",
       "      <td>the guy is a walk sugar cooki</td>\n",
       "      <td>the guy is a walking sugar cookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>claire mccaskill on twitter when  agents were ...</td>\n",
       "      <td>clair mccaskil on twitter when  agent were mak...</td>\n",
       "      <td>claire mccaskill on twitter when  agent were m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>southfield city clerk charged with  felonies t...</td>\n",
       "      <td>southfield citi clerk charg with  feloni tie t...</td>\n",
       "      <td>southfield city clerk charged with  felony tie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>amy siskind on the eve of the second mass shoo...</td>\n",
       "      <td>ami siskind on the eve of the second mass shoo...</td>\n",
       "      <td>amy siskind on the eve of the second mass shoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>hmmm and they call  fascist</td>\n",
       "      <td>hmmm and they call  fascist</td>\n",
       "      <td>hmmm and they call  fascist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    combine_text_tokens  \\\n",
       "615                   the guy is a walking sugar cookie   \n",
       "526   claire mccaskill on twitter when  agents were ...   \n",
       "1715  southfield city clerk charged with  felonies t...   \n",
       "715   amy siskind on the eve of the second mass shoo...   \n",
       "1806                        hmmm and they call  fascist   \n",
       "\n",
       "                                      combine_text_stem  \\\n",
       "615                       the guy is a walk sugar cooki   \n",
       "526   clair mccaskil on twitter when  agent were mak...   \n",
       "1715  southfield citi clerk charg with  feloni tie t...   \n",
       "715   ami siskind on the eve of the second mass shoo...   \n",
       "1806                        hmmm and they call  fascist   \n",
       "\n",
       "                                     combine_text_lemma  \n",
       "615                   the guy is a walking sugar cookie  \n",
       "526   claire mccaskill on twitter when  agent were m...  \n",
       "1715  southfield city clerk charged with  felony tie...  \n",
       "715   amy siskind on the eve of the second mass shoo...  \n",
       "1806                        hmmm and they call  fascist  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train['combine_text_tokens'].values.astype('U')\n",
    "X_test_final = X_test['combine_text_tokens'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selections: \n",
    "#### 1.  TF-IDF Vectorizer Multinomial Naive-Bayes\n",
    "  - `tf__ngram_range = (1, 2)`\n",
    "  - `tf__stop_words = 'english'`\n",
    "  \n",
    "#### 2. TF-IDF Vectorizer Scaled Logistic Regression\n",
    "  - `tf__ngram_range = (1, 2)`\n",
    "  - `tf__stop_words = 'english'`\n",
    "  \n",
    "#### 3. TF-IDF Vectorizer Random Forest \n",
    "  - `tf__ngram_range = (1, 1)`\n",
    "  - `tf__stop_words = 'english'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_loop = pd.DataFrame(columns = ['train_accuracy', 'test_accuracy', 'best_params', 'tn', 'fp', 'fn', 'tp',\n",
    "                                   'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_steps = [('tf', TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2))),\n",
    "             ('mnb', MultinomialNB())]\n",
    "\n",
    "mnb_params = {\"mnb__alpha\": np.arange(.1, 1, .1),\n",
    "              \"tf__max_features\": [30000, 32500, 35000, 37500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_params_1 = {\"mnb__alpha\": np.arange(.01, 1, .1),\n",
    "                \"tf__max_features\": [22500, 25000, 27500, 30000, 32500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_params_2 = {\"mnb__alpha\": np.arange(.01, 0.5, .05),\n",
    "                \"tf__max_features\": [22500, 25000, 27500, 30000, 32500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(mnb_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnb_pipe(params):\n",
    "    mnb_results = {}\n",
    "\n",
    "    grid = GridSearchCV(pipe, params, cv = 5) # optimize GridSearch hyperparameters on `cv=5` cross validation runs\n",
    "    grid.fit(X_train_final, y_train.values.ravel()) # fit to our training data\n",
    "\n",
    "    print('Train Accuracy: ', grid.score(X_train_final, y_train))\n",
    "    mnb_results['train_accuracy'] = grid.score(X_train_final, y_train) # print/store training accuracy\n",
    "\n",
    "    print('Test Accuracy: ',grid.score(X_test_final, y_test))\n",
    "    mnb_results['test_accuracy'] = grid.score(X_test_final, y_test) # print/store test accuracy\n",
    "\n",
    "    print('Best Params: ',grid.best_params_, '\\n')\n",
    "    mnb_results['best_params'] = grid.best_params_ # print/store best parameters\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_final)).ravel() # inspect counted results in matrix\n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    mnb_results['tn'] = tn\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    mnb_results['fp'] = fp\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    mnb_results['fn'] = fn\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    mnb_results['tp'] = tp\n",
    "\n",
    "    print(\"Precision Score: \", precision_score(y_test, grid.predict(X_test_final)))\n",
    "    mnb_results['precision'] = precision_score(y_test, grid.predict(X_test_final))\n",
    "\n",
    "    print(\"Recall Score: \", recall_score(y_test, grid.predict(X_test_final)))\n",
    "    mnb_results['recall'] = recall_score(y_test, grid.predict(X_test_final))\n",
    "\n",
    "    print(\"F1 Score: \", f1_score(y_test, grid.predict(X_test_final)), '\\n')\n",
    "    mnb_results['f1'] = f1_score(y_test, grid.predict(X_test_final))\n",
    "    \n",
    "    return mnb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9946559786239145\n",
      "Test Accuracy:  0.744\n",
      "Best Params:  {'mnb__alpha': 0.2, 'tf__max_features': 30000} \n",
      "\n",
      "True Negatives: 197\n",
      "False Positives: 53\n",
      "False Negatives: 75\n",
      "True Positives: 175 \n",
      "\n",
      "Precision Score:  0.7675438596491229\n",
      "Recall Score:  0.7\n",
      "F1 Score:  0.7322175732217573 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_results = mnb_pipe(mnb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_loop = mnb_loop.append(mnb_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9946559786239145\n",
      "Test Accuracy:  0.746\n",
      "Best Params:  {'mnb__alpha': 0.21000000000000002, 'tf__max_features': 22500} \n",
      "\n",
      "True Negatives: 197\n",
      "False Positives: 53\n",
      "False Negatives: 74\n",
      "True Positives: 176 \n",
      "\n",
      "Precision Score:  0.7685589519650655\n",
      "Recall Score:  0.704\n",
      "F1 Score:  0.7348643006263048 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_results = mnb_pipe(mnb_params_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_loop = mnb_loop.append(mnb_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9946559786239145\n",
      "Test Accuracy:  0.746\n",
      "Best Params:  {'mnb__alpha': 0.21000000000000002, 'tf__max_features': 22500} \n",
      "\n",
      "True Negatives: 197\n",
      "False Positives: 53\n",
      "False Negatives: 74\n",
      "True Positives: 176 \n",
      "\n",
      "Precision Score:  0.7685589519650655\n",
      "Recall Score:  0.704\n",
      "F1 Score:  0.7348643006263048 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_results = mnb_pipe(mnb_params_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_loop = mnb_loop.append(mnb_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994656</td>\n",
       "      <td>0.744</td>\n",
       "      <td>{'mnb__alpha': 0.2, 'tf__max_features': 30000}</td>\n",
       "      <td>197</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>175</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.732218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994656</td>\n",
       "      <td>0.746</td>\n",
       "      <td>{'mnb__alpha': 0.21000000000000002, 'tf__max_f...</td>\n",
       "      <td>197</td>\n",
       "      <td>53</td>\n",
       "      <td>74</td>\n",
       "      <td>176</td>\n",
       "      <td>0.768559</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.734864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994656</td>\n",
       "      <td>0.746</td>\n",
       "      <td>{'mnb__alpha': 0.21000000000000002, 'tf__max_f...</td>\n",
       "      <td>197</td>\n",
       "      <td>53</td>\n",
       "      <td>74</td>\n",
       "      <td>176</td>\n",
       "      <td>0.768559</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.734864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.994656          0.744   \n",
       "1        0.994656          0.746   \n",
       "2        0.994656          0.746   \n",
       "\n",
       "                                         best_params   tn  fp  fn   tp  \\\n",
       "0     {'mnb__alpha': 0.2, 'tf__max_features': 30000}  197  53  75  175   \n",
       "1  {'mnb__alpha': 0.21000000000000002, 'tf__max_f...  197  53  74  176   \n",
       "2  {'mnb__alpha': 0.21000000000000002, 'tf__max_f...  197  53  74  176   \n",
       "\n",
       "   precision  recall        f1  \n",
       "0   0.767544   0.700  0.732218  \n",
       "1   0.768559   0.704  0.734864  \n",
       "2   0.768559   0.704  0.734864  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_loop = pd.DataFrame(columns = ['train_accuracy', 'test_accuracy', 'best_params', 'tn', 'fp', 'fn', 'tp',\n",
    "                                  'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_steps = [('tf', TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2))),\n",
    "            ('sc', StandardScaler(with_mean = False)),\n",
    "            ('lr', LogisticRegression(random_state = 42))]\n",
    "\n",
    "lr_params = {\"lr__penalty\": ['l2'], \"lr__C\": [1.2],\n",
    "             \"lr__tol\": [.00035], \"tf__max_features\": [25000, 27500, 30000, 32500, 35000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params_1 = {\"lr__penalty\": ['l2'], \"lr__C\": [1.2],\n",
    "               \"lr__tol\": [.00035], \"tf__max_features\": [15000, 17500, 20000, 22500, 25000, 27500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params_2 = {\"lr__penalty\": ['l1'], \"lr__C\": [1, 1.2], \"lr__solver\": ['liblinear'],\n",
    "               \"lr__tol\": [.00035], \"tf__max_features\": [14000, 15000, 16000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params_3 = {\"lr__penalty\": ['l1'], \"lr__C\": [1, 1.2], \"lr__solver\": ['liblinear'],\n",
    "               \"lr__tol\": [.00035], \"tf__max_features\": [12000, 13000, 14000, 15000, 16000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(lr_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_pipe(params):\n",
    "    lr_results = {}\n",
    "\n",
    "    grid = GridSearchCV(pipe, params, cv = 5) # optimize GridSearch hyperparameters on `cv=5` cross validation runs\n",
    "    grid.fit(X_train_final, y_train.values.ravel()) # fit to our training data\n",
    "\n",
    "    print('Train Accuracy: ', grid.score(X_train_final, y_train))\n",
    "    lr_results['train_accuracy'] = grid.score(X_train_final, y_train) # print/store training accuracy\n",
    "\n",
    "    print('Test Accuracy: ',grid.score(X_test_final, y_test))\n",
    "    lr_results['test_accuracy'] = grid.score(X_test_final, y_test) # print/store test accuracy\n",
    "\n",
    "    print('Best Params: ',grid.best_params_, '\\n')\n",
    "    lr_results['best_params'] = grid.best_params_ # print/store best parameters\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_final)).ravel() # inspect counted results in matrix\n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    lr_results['tn'] = tn\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    lr_results['fp'] = fp\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    lr_results['fn'] = fn\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    lr_results['tp'] = tp\n",
    "\n",
    "    print(\"Precision Score: \", precision_score(y_test, grid.predict(X_test_final)))\n",
    "    lr_results['precision'] = precision_score(y_test, grid.predict(X_test_final))\n",
    "\n",
    "    print(\"Recall Score: \", recall_score(y_test, grid.predict(X_test_final)))\n",
    "    lr_results['recall'] = recall_score(y_test, grid.predict(X_test_final))\n",
    "\n",
    "    print(\"F1 Score: \", f1_score(y_test, grid.predict(X_test_final)), '\\n')\n",
    "    lr_results['f1'] = f1_score(y_test, grid.predict(X_test_final))\n",
    "    \n",
    "    return lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9966599866399466\n",
      "Test Accuracy:  0.722\n",
      "Best Params:  {'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol': 0.00035, 'tf__max_features': 25000} \n",
      "\n",
      "True Negatives: 172\n",
      "False Positives: 78\n",
      "False Negatives: 61\n",
      "True Positives: 189 \n",
      "\n",
      "Precision Score:  0.7078651685393258\n",
      "Recall Score:  0.756\n",
      "F1 Score:  0.7311411992263056 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_results = lr_pipe(lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_loop = lr_loop.append(lr_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9959919839679359\n",
      "Test Accuracy:  0.712\n",
      "Best Params:  {'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol': 0.00035, 'tf__max_features': 17500} \n",
      "\n",
      "True Negatives: 171\n",
      "False Positives: 79\n",
      "False Negatives: 65\n",
      "True Positives: 185 \n",
      "\n",
      "Precision Score:  0.7007575757575758\n",
      "Recall Score:  0.74\n",
      "F1 Score:  0.7198443579766536 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_results = lr_pipe(lr_params_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_loop = lr_loop.append(lr_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9953239812959251\n",
      "Test Accuracy:  0.726\n",
      "Best Params:  {'lr__C': 1, 'lr__penalty': 'l1', 'lr__solver': 'liblinear', 'lr__tol': 0.00035, 'tf__max_features': 15000} \n",
      "\n",
      "True Negatives: 193\n",
      "False Positives: 57\n",
      "False Negatives: 80\n",
      "True Positives: 170 \n",
      "\n",
      "Precision Score:  0.748898678414097\n",
      "Recall Score:  0.68\n",
      "F1 Score:  0.7127882599580714 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_results = lr_pipe(lr_params_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_loop = lr_loop.append(lr_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996660</td>\n",
       "      <td>0.722</td>\n",
       "      <td>{'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol':...</td>\n",
       "      <td>172</td>\n",
       "      <td>78</td>\n",
       "      <td>61</td>\n",
       "      <td>189</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995992</td>\n",
       "      <td>0.712</td>\n",
       "      <td>{'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol':...</td>\n",
       "      <td>171</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>185</td>\n",
       "      <td>0.700758</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.719844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995324</td>\n",
       "      <td>0.726</td>\n",
       "      <td>{'lr__C': 1, 'lr__penalty': 'l1', 'lr__solver'...</td>\n",
       "      <td>193</td>\n",
       "      <td>57</td>\n",
       "      <td>80</td>\n",
       "      <td>170</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.712788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.996660          0.722   \n",
       "1        0.995992          0.712   \n",
       "2        0.995324          0.726   \n",
       "\n",
       "                                         best_params   tn  fp  fn   tp  \\\n",
       "0  {'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol':...  172  78  61  189   \n",
       "1  {'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol':...  171  79  65  185   \n",
       "2  {'lr__C': 1, 'lr__penalty': 'l1', 'lr__solver'...  193  57  80  170   \n",
       "\n",
       "   precision  recall        f1  \n",
       "0   0.707865   0.756  0.731141  \n",
       "1   0.700758   0.740  0.719844  \n",
       "2   0.748899   0.680  0.712788  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_loop = pd.DataFrame(columns = ['train_accuracy', 'test_accuracy', 'best_params', 'tn', 'fp', 'fn', 'tp',\n",
    "                                  'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_steps = [('tf', TfidfVectorizer(stop_words = 'english', ngram_range = (1, 1))),\n",
    "            ('rf', RandomForestClassifier(random_state = 42))]\n",
    "\n",
    "rf_params = {\"rf__n_estimators\": np.arange(98, 102, 1), \"rf__max_depth\": [7, 8, 9], \n",
    "             \"rf__criterion\": ['gini'], \"tf__max_features\": [None, 35000, 40000, 45000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params_1 = {\"rf__n_estimators\": np.arange(94, 98, 1), \"rf__max_depth\": [5, 6, 7], \n",
    "               \"rf__criterion\": ['gini'], \"tf__max_features\": [None, 2500, 5000, 7500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params_2 = {\"rf__n_estimators\": np.arange(100, 104, 1), \"rf__max_depth\": [6, 7, 8, 9], \n",
    "               \"rf__criterion\": ['gini'], \"tf__max_features\": [None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(rf_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_pipe(params):\n",
    "    rf_results = {}\n",
    "\n",
    "    grid = GridSearchCV(pipe, params, cv = 5) # optimize GridSearch hyperparameters on `cv=5` cross validation runs\n",
    "    grid.fit(X_train_final, y_train.values.ravel()) # fit to our training data\n",
    "\n",
    "    print('Train Accuracy: ', grid.score(X_train_final, y_train))\n",
    "    rf_results['train_accuracy'] = grid.score(X_train_final, y_train) # print/store training accuracy\n",
    "\n",
    "    print('Test Accuracy: ',grid.score(X_test_final, y_test))\n",
    "    rf_results['test_accuracy'] = grid.score(X_test_final, y_test) # print/store test accuracy\n",
    "\n",
    "    print('Best Params: ',grid.best_params_, '\\n')\n",
    "    rf_results['best_params'] = grid.best_params_ # print/store best parameters\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_final)).ravel() # inspect counted results in matrix\n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    rf_results['tn'] = tn\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    rf_results['fp'] = fp\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    rf_results['fn'] = fn\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    rf_results['tp'] = tp\n",
    "\n",
    "    print(\"Precision Score: \", precision_score(y_test, grid.predict(X_test_final)))\n",
    "    rf_results['precision'] = precision_score(y_test, grid.predict(X_test_final))\n",
    "\n",
    "    print(\"Recall Score: \", recall_score(y_test, grid.predict(X_test_final)))\n",
    "    rf_results['recall'] = recall_score(y_test, grid.predict(X_test_final))\n",
    "\n",
    "    print(\"F1 Score: \", f1_score(y_test, grid.predict(X_test_final)), '\\n')\n",
    "    rf_results['f1'] = f1_score(y_test, grid.predict(X_test_final))\n",
    "    \n",
    "    return rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.7895791583166333\n",
      "Test Accuracy:  0.708\n",
      "Best Params:  {'rf__criterion': 'gini', 'rf__max_depth': 9, 'rf__n_estimators': 98, 'tf__max_features': None} \n",
      "\n",
      "True Negatives: 162\n",
      "False Positives: 88\n",
      "False Negatives: 58\n",
      "True Positives: 192 \n",
      "\n",
      "Precision Score:  0.6857142857142857\n",
      "Recall Score:  0.768\n",
      "F1 Score:  0.7245283018867925 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_results = rf_pipe(rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_loop = rf_loop.append(rf_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789579</td>\n",
       "      <td>0.708</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 9, ...</td>\n",
       "      <td>162</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>192</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.724528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.789579          0.708   \n",
       "\n",
       "                                         best_params   tn  fp  fn   tp  \\\n",
       "0  {'rf__criterion': 'gini', 'rf__max_depth': 9, ...  162  88  58  192   \n",
       "\n",
       "   precision  recall        f1  \n",
       "0   0.685714   0.768  0.724528  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.7735470941883767\n",
      "Test Accuracy:  0.716\n",
      "Best Params:  {'rf__criterion': 'gini', 'rf__max_depth': 7, 'rf__n_estimators': 96, 'tf__max_features': 2500} \n",
      "\n",
      "True Negatives: 172\n",
      "False Positives: 78\n",
      "False Negatives: 64\n",
      "True Positives: 186 \n",
      "\n",
      "Precision Score:  0.7045454545454546\n",
      "Recall Score:  0.744\n",
      "F1 Score:  0.7237354085603113 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_results = rf_pipe(rf_params_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_loop = rf_loop.append(rf_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.7895791583166333\n",
      "Test Accuracy:  0.712\n",
      "Best Params:  {'rf__criterion': 'gini', 'rf__max_depth': 9, 'rf__n_estimators': 102, 'tf__max_features': None} \n",
      "\n",
      "True Negatives: 161\n",
      "False Positives: 89\n",
      "False Negatives: 55\n",
      "True Positives: 195 \n",
      "\n",
      "Precision Score:  0.6866197183098591\n",
      "Recall Score:  0.78\n",
      "F1 Score:  0.7303370786516854 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_results = rf_pipe(rf_params_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_loop = rf_loop.append(rf_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789579</td>\n",
       "      <td>0.708</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 9, ...</td>\n",
       "      <td>162</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>192</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.724528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.773547</td>\n",
       "      <td>0.716</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 7, ...</td>\n",
       "      <td>172</td>\n",
       "      <td>78</td>\n",
       "      <td>64</td>\n",
       "      <td>186</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.723735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.789579</td>\n",
       "      <td>0.712</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 9, ...</td>\n",
       "      <td>161</td>\n",
       "      <td>89</td>\n",
       "      <td>55</td>\n",
       "      <td>195</td>\n",
       "      <td>0.686620</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.730337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.789579          0.708   \n",
       "1        0.773547          0.716   \n",
       "2        0.789579          0.712   \n",
       "\n",
       "                                         best_params   tn  fp  fn   tp  \\\n",
       "0  {'rf__criterion': 'gini', 'rf__max_depth': 9, ...  162  88  58  192   \n",
       "1  {'rf__criterion': 'gini', 'rf__max_depth': 7, ...  172  78  64  186   \n",
       "2  {'rf__criterion': 'gini', 'rf__max_depth': 9, ...  161  89  55  195   \n",
       "\n",
       "   precision  recall        f1  \n",
       "0   0.685714   0.768  0.724528  \n",
       "1   0.704545   0.744  0.723735  \n",
       "2   0.686620   0.780  0.730337  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** - How many posts (r/democrats or r/Republican) did we correctly predict out of all the posts? (TP + TN / TP + FP + TN + FN)    \n",
    "**Precision** - How many posts of those we labeled as democrats are actually democrats post? (TP / TP + FP)  \n",
    "**Recall/Sensitivity** - Of all the democrats posts how many did we correctly predict? (TP / TP + FN)     \n",
    "**F1-score** - It is the harmonic mean of precision and recall (2 * (Recall * Precision) / (Recall + Precision))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994656</td>\n",
       "      <td>0.746</td>\n",
       "      <td>{'mnb__alpha': 0.21000000000000002, 'tf__max_f...</td>\n",
       "      <td>197</td>\n",
       "      <td>53</td>\n",
       "      <td>74</td>\n",
       "      <td>176</td>\n",
       "      <td>0.768559</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.734864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994656</td>\n",
       "      <td>0.746</td>\n",
       "      <td>{'mnb__alpha': 0.21000000000000002, 'tf__max_f...</td>\n",
       "      <td>197</td>\n",
       "      <td>53</td>\n",
       "      <td>74</td>\n",
       "      <td>176</td>\n",
       "      <td>0.768559</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.734864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994656</td>\n",
       "      <td>0.744</td>\n",
       "      <td>{'mnb__alpha': 0.2, 'tf__max_features': 30000}</td>\n",
       "      <td>197</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>175</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.732218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "1        0.994656          0.746   \n",
       "2        0.994656          0.746   \n",
       "0        0.994656          0.744   \n",
       "\n",
       "                                         best_params   tn  fp  fn   tp  \\\n",
       "1  {'mnb__alpha': 0.21000000000000002, 'tf__max_f...  197  53  74  176   \n",
       "2  {'mnb__alpha': 0.21000000000000002, 'tf__max_f...  197  53  74  176   \n",
       "0     {'mnb__alpha': 0.2, 'tf__max_features': 30000}  197  53  75  175   \n",
       "\n",
       "   precision  recall        f1  \n",
       "1   0.768559   0.704  0.734864  \n",
       "2   0.768559   0.704  0.734864  \n",
       "0   0.767544   0.700  0.732218  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_loop.sort_values('test_accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index 1 is choosen out of all the Multinomial Naive-Bayes models apart from looking at the test accuracy score, it is important to also evaluate both the precision and recall of the model we can see that it also out performance the other runs by score the highest F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995324</td>\n",
       "      <td>0.726</td>\n",
       "      <td>{'lr__C': 1, 'lr__penalty': 'l1', 'lr__solver'...</td>\n",
       "      <td>193</td>\n",
       "      <td>57</td>\n",
       "      <td>80</td>\n",
       "      <td>170</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.712788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996660</td>\n",
       "      <td>0.722</td>\n",
       "      <td>{'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol':...</td>\n",
       "      <td>172</td>\n",
       "      <td>78</td>\n",
       "      <td>61</td>\n",
       "      <td>189</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995992</td>\n",
       "      <td>0.712</td>\n",
       "      <td>{'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol':...</td>\n",
       "      <td>171</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>185</td>\n",
       "      <td>0.700758</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.719844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "2        0.995324          0.726   \n",
       "0        0.996660          0.722   \n",
       "1        0.995992          0.712   \n",
       "\n",
       "                                         best_params   tn  fp  fn   tp  \\\n",
       "2  {'lr__C': 1, 'lr__penalty': 'l1', 'lr__solver'...  193  57  80  170   \n",
       "0  {'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol':...  172  78  61  189   \n",
       "1  {'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol':...  171  79  65  185   \n",
       "\n",
       "   precision  recall        f1  \n",
       "2   0.748899   0.680  0.712788  \n",
       "0   0.707865   0.756  0.731141  \n",
       "1   0.700758   0.740  0.719844  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_loop.sort_values('test_accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index 0 is choosen out of all the Logistic Regression models although it does not have the highest test accuracy score, upon further inspection of the precision, recall and F1-score we can see that it actually outperforms the higher test accuracy score of Index 2 model. We decided to pick the model with a higher F1-score as this means it is capable of getting a more accuracy prediction for post on democrats subreddit which is our focus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.773547</td>\n",
       "      <td>0.716</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 7, ...</td>\n",
       "      <td>172</td>\n",
       "      <td>78</td>\n",
       "      <td>64</td>\n",
       "      <td>186</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.723735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.789579</td>\n",
       "      <td>0.712</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 9, ...</td>\n",
       "      <td>161</td>\n",
       "      <td>89</td>\n",
       "      <td>55</td>\n",
       "      <td>195</td>\n",
       "      <td>0.686620</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.730337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789579</td>\n",
       "      <td>0.708</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 9, ...</td>\n",
       "      <td>162</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>192</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.724528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "1        0.773547          0.716   \n",
       "2        0.789579          0.712   \n",
       "0        0.789579          0.708   \n",
       "\n",
       "                                         best_params   tn  fp  fn   tp  \\\n",
       "1  {'rf__criterion': 'gini', 'rf__max_depth': 7, ...  172  78  64  186   \n",
       "2  {'rf__criterion': 'gini', 'rf__max_depth': 9, ...  161  89  55  195   \n",
       "0  {'rf__criterion': 'gini', 'rf__max_depth': 9, ...  162  88  58  192   \n",
       "\n",
       "   precision  recall        f1  \n",
       "1   0.704545   0.744  0.723735  \n",
       "2   0.686620   0.780  0.730337  \n",
       "0   0.685714   0.768  0.724528  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_loop.sort_values('test_accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index 1 scored higher compared to index 2 in terms of the test accuracy score, however, between the two index 2 has a higher F1-socre as it means it is capable of getting a more accurate prediction for post on democrats subreddict which is our focus. Hence index 2 final parameters is choosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994656</td>\n",
       "      <td>0.746</td>\n",
       "      <td>{'mnb__alpha': 0.21000000000000002, 'tf__max_f...</td>\n",
       "      <td>197</td>\n",
       "      <td>53</td>\n",
       "      <td>74</td>\n",
       "      <td>176</td>\n",
       "      <td>0.768559</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.734864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "2        0.994656          0.746   \n",
       "\n",
       "                                         best_params   tn  fp  fn   tp  \\\n",
       "2  {'mnb__alpha': 0.21000000000000002, 'tf__max_f...  197  53  74  176   \n",
       "\n",
       "   precision  recall        f1  \n",
       "2   0.768559   0.704  0.734864  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_loop[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = pd.concat([mnb_loop[1:2], lr_loop[:1], rf_loop[2:3]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994656</td>\n",
       "      <td>0.746</td>\n",
       "      <td>{'mnb__alpha': 0.21000000000000002, 'tf__max_f...</td>\n",
       "      <td>197</td>\n",
       "      <td>53</td>\n",
       "      <td>74</td>\n",
       "      <td>176</td>\n",
       "      <td>0.768559</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.734864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996660</td>\n",
       "      <td>0.722</td>\n",
       "      <td>{'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol':...</td>\n",
       "      <td>172</td>\n",
       "      <td>78</td>\n",
       "      <td>61</td>\n",
       "      <td>189</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.789579</td>\n",
       "      <td>0.712</td>\n",
       "      <td>{'rf__criterion': 'gini', 'rf__max_depth': 9, ...</td>\n",
       "      <td>161</td>\n",
       "      <td>89</td>\n",
       "      <td>55</td>\n",
       "      <td>195</td>\n",
       "      <td>0.686620</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.730337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "1        0.994656          0.746   \n",
       "0        0.996660          0.722   \n",
       "2        0.789579          0.712   \n",
       "\n",
       "                                         best_params   tn  fp  fn   tp  \\\n",
       "1  {'mnb__alpha': 0.21000000000000002, 'tf__max_f...  197  53  74  176   \n",
       "0  {'lr__C': 1.2, 'lr__penalty': 'l2', 'lr__tol':...  172  78  61  189   \n",
       "2  {'rf__criterion': 'gini', 'rf__max_depth': 9, ...  161  89  55  195   \n",
       "\n",
       "   precision  recall        f1  \n",
       "1   0.768559   0.704  0.734864  \n",
       "0   0.707865   0.756  0.731141  \n",
       "2   0.686620   0.780  0.730337  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.sort_values('test_accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the final models selected for the individual model types, Random Forest model is first dropped. We then look to evaluate the Multinomial Naive-Bayes model and Logistic Regressions model. Looking all the metrics for comparison we can see that the Multinomial Naive-Bayes model outperforms the Logistic Regressions model. Hence, our final selection will be the Multinomial Naive-Bayes model with `alpha: 0.21` and `max_features = 22500`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_steps = [('tf', TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2), max_features = 22500)),\n",
    "               ('mnb', MultinomialNB(alpha = 0.21))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(final_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=22500,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('mnb',\n",
       "                 MultinomialNB(alpha=0.21, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train_final, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946559786239145"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = pipe.named_steps['mnb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vec = pipe.named_steps['tf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1497x18544 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 29683 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_vec.fit_transform(X_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model_df = pd.DataFrame(selected_model.coef_.T, index = selected_vec.get_feature_names(), columns = ['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trump       -6.361883\n",
       "black       -7.025105\n",
       "media       -7.032372\n",
       "biden       -7.041769\n",
       "president   -7.236651\n",
       "like        -7.269424\n",
       "left        -7.295475\n",
       "new         -7.338719\n",
       "joe         -7.349093\n",
       "people      -7.359577\n",
       "Name: coef, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_model_df.coef.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function researched and borrowed from Stackoverflow\n",
    "# https://stackoverflow.com/questions/11116697/how-to-get-most-informative-features-for-scikit-learn-classifiers\n",
    "\n",
    "def important_features(vectorizer, classifier, n = 20):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.feature_count_[0], feature_names), reverse = True)[:n]\n",
    "    topn_class2 = sorted(zip(classifier.feature_count_[1], feature_names), reverse = True)[:n]\n",
    "    print(\"Important words for r/Republican\\n\")\n",
    "    for coef, feat in topn_class1:\n",
    "        print(class_labels[0], coef, feat)\n",
    "    print(\"-----------------------------------------\\n\")\n",
    "    print(\"Important words for r/democrats\\n\")\n",
    "    for coef, feat in topn_class2:\n",
    "        print(class_labels[1], coef, feat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important words for r/Republican\n",
      "\n",
      "0 24.101323119490903 trump\n",
      "0 8.523535229197075 president\n",
      "0 7.517688689080907 twitter\n",
      "0 5.588794782007526 donald\n",
      "0 5.551203193684958 says\n",
      "0 5.516157499149025 donald trump\n",
      "0 5.507025891187277 vote\n",
      "0 5.455446317451146 gop\n",
      "0 5.221953423854521 people\n",
      "0 5.016747455609432 obama\n",
      "0 4.7216884543495565 house\n",
      "0 4.40920412953961 clinton\n",
      "0 4.366930702089541 campaign\n",
      "0 3.9816754552585594 hillary\n",
      "0 3.929695598111138 new\n",
      "-----------------------------------------\n",
      "\n",
      "Important words for r/democrats\n",
      "\n",
      "1 11.077877017130145 trump\n",
      "1 5.605385911379153 black\n",
      "1 5.563278093974671 media\n",
      "1 5.509282903760532 biden\n",
      "1 4.496579039463293 president\n",
      "1 4.344831980523482 like\n",
      "1 4.227705256391047 left\n",
      "1 4.039891621072071 new\n",
      "1 3.9960326234330528 joe\n",
      "1 3.9521665022616954 people\n",
      "1 3.9476687337660734 says\n",
      "1 3.6770328184155217 antifa\n",
      "1 3.5774170319809064 don\n",
      "1 3.5754855064920537 china\n",
      "1 3.4722865777886565 just\n"
     ]
    }
   ],
   "source": [
    "important_features(selected_vec, selected_model, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our findings, we were able to answer the questions that we have formulated as part of the problem statement.  \n",
    "- Between the two similar subreddits r/democrats and r/Republican are able to differentiate the post using Natural Language Processing models?    \n",
    "\n",
    "Yes we were able to differentiate the post between the two different subreddits and compared to our baseline score of 50.025% we were able to improve it to 74.6%. However, due to the overlap nature of some major key words this has likely reduce the performance of our models.  \n",
    "- Which models is then likely to work best?  \n",
    "\n",
    "Multinomial Naive-Bayes model seems to works the best after evaluating the metrics for accuracy, precision, recall and f1-score across the 3 different models that were utilised. \n",
    "\n",
    "While we have managed to answer our problem statement that we have formulated, there is still room for improvement. Particularly in terms of the final selected model there is a huge different between the train and test score this is likely due to overfitting. We can take a few steps to further improve the model\n",
    "\n",
    "1. Increase data size of collection by utilising pushshift.io which is an alternative reddit API that is capable of exceeding the 1000 post limit [source](https://pushshift.io/).\n",
    "2. Collect additional text information like comments from the individual reddit post\n",
    "3. Explore more alternative social media platforms like twitter or facebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
